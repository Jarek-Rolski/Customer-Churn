{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac26dec7-0e24-4d8b-835b-306a866ed4b1",
   "metadata": {},
   "source": [
    "# \"The Thera bank\" Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8d00a3-af0d-4040-98e0-0c79823b791b",
   "metadata": {},
   "source": [
    "In these notebook I create XGBoost model predicting customers willing to churn. Metric of my concern is Logloss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ae2711-fd73-4ac6-aa07-3e1504be587d",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ab54233-4957-415b-9f38-359ac138dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['PWD'],'scripts'))\n",
    "from Data_Prep import Data_Prep\n",
    "from utils import get_metrics_score\n",
    "from utils import make_confusion_matrix\n",
    "\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "import ray\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b71fa48-baa4-434d-98f4-3acdabd28e92",
   "metadata": {},
   "source": [
    "## Load and split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb43cbcd-9dae-4c4c-ae18-50539d005ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(os.environ['PWD'],'data/train.csv'))\n",
    "\n",
    "X_train = train.drop('Attrition_Flag',axis=1)\n",
    "y_train = train['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1}).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921f6a10-8b6d-4cff-b67c-8c1c5eff671f",
   "metadata": {},
   "source": [
    "## Finding the best sampling method for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a3aa5f-3f72-4214-ad96-323403ce0fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_original = Pipeline([('dp', Data_Prep()), \n",
    "                      ('xgb', XGBClassifier(random_state=1, eval_metric='logloss', use_label_encoder=False))])\n",
    "\n",
    "estimator_rus = Pipeline([('dp', Data_Prep()), ('rus', RandomUnderSampler()), \n",
    "                      ('xgb', XGBClassifier(random_state=1, eval_metric='logloss', use_label_encoder=False))])\n",
    "\n",
    "estimator_ros = Pipeline([('dp', Data_Prep()), ('ros', RandomOverSampler()), \n",
    "                      ('xgb', XGBClassifier(random_state=1, eval_metric='logloss', use_label_encoder=False))])\n",
    "\n",
    "estimator_tl = Pipeline([('dp', Data_Prep()), ('tl', TomekLinks()), \n",
    "                      ('xgb', XGBClassifier(random_state=1, eval_metric='logloss', use_label_encoder=False))])\n",
    "\n",
    "estimators = [estimator_original, estimator_rus, estimator_ros, estimator_tl]\n",
    "sampling = ['original', 'rus', 'ros', 'tl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c45d05e-3879-4c24-ab06-3d2c76ee9ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/opt/conda/lib/python3.9/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "ll_scorer = metrics.make_scorer(metrics.log_loss, greater_is_better=False, needs_proba=True)\n",
    "scores = []\n",
    "for estimator in estimators:\n",
    "    cv_results = cross_validate(estimator, X=X_train, y=y_train, scoring=ll_scorer, cv=5, n_jobs=-1)\n",
    "    scores.append(np.mean(cv_results['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34ac0c19-fe1c-4b91-8008-9ec910ebd6fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original  :  -0.08372492464766643\n",
      "rus  :  -0.15048604124570958\n",
      "ros  :  -0.08123964061243064\n",
      "tl  :  -0.08317300991686573\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(sampling,scores):\n",
    "    print(i,' : ', j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18e5ba1-1563-418a-ba23-da873fe36529",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning of XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d983f39a-88d8-4625-91db-482c70152c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 17:12:19,828\tWARNING services.py:1856 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67010560 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=3.37gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n"
     ]
    }
   ],
   "source": [
    "# Prepare data reference for tuning client\n",
    "object_ref_X_train = ray.put(X_train)\n",
    "object_ref_y_train = ray.put(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9f22a40-63db-444f-8532-5df25728756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_scorer = metrics.make_scorer(metrics.log_loss, greater_is_better=False, needs_proba=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e55cef-6317-4c42-93d2-fdc74ea51fbf",
   "metadata": {},
   "source": [
    "Hyperparameter tuning using ray-tune library and optimization algorithm HyperOptSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a36ee6b8-07ae-4899-9476-2adc333d76fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-02-16 17:53:34 (running for 00:36:44.10)<br>Memory usage on this node: 2.4/12.4 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/6.12 GiB heap, 0.0/3.06 GiB objects<br>Current best trial: 35251870 with Logloss Test=-0.08216509185497263 and parameters={'n_estimators': 118, 'gamma': 0.23235727610719414, 'subsample': 0.78, 'colsample_bytree': 0.8, 'colsample_bylevel': 0.87, 'learning_rate': 0.1}<br>Result logdir: /usr/src/app/data/ray_results/XGBoost_ros_tuning<br>Number of trials: 48/48 (48 TERMINATED)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-16 17:53:34,834\tINFO tune.py:636 -- Total run time: 2204.67 seconds (2204.05 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "def training_function(config):\n",
    "    # Hyperparameters\n",
    "    config['n_estimators'] = int(config['n_estimators'])      \n",
    "    config['learning_rate'] = 10 ** config['learning_rate']\n",
    "                                           \n",
    "    X_train=ray.get(object_ref_X_train)\n",
    "    y_train=ray.get(object_ref_y_train)\n",
    "    \n",
    "    sys.path.append( os.path.join(os.environ['PWD'],'scripts'))\n",
    "    from Data_Prep import Data_Prep\n",
    "\n",
    "    estimator = Pipeline([('dp', Data_Prep()), ('ros', RandomOverSampler()), \n",
    "                          ('xgb', XGBClassifier(random_state=1, eval_metric='logloss', use_label_encoder=False, **config))])\n",
    "    \n",
    "    cv_results = cross_validate(estimator, X_train, y_train, scoring=ll_scorer, cv=3, return_train_score=True)\n",
    "\n",
    "    d = {'Logloss Training':np.mean(cv_results['train_score']), 'Logloss Test':np.mean(cv_results['test_score'])}\n",
    "    \n",
    "    tune.report(**d)\n",
    "\n",
    "config = {\n",
    "    \"n_estimators\": tune.randint(80, 120),\n",
    "    \"gamma\": tune.uniform(0, 3),\n",
    "    \"subsample\": tune.quniform(0.7, 0.95, 0.01),\n",
    "    \"colsample_bytree\": tune.quniform(0.7, 0.95, 0.01),\n",
    "    \"colsample_bylevel\": tune.quniform(0.7, 0.95, 0.01),    \n",
    "    \"learning_rate\": tune.quniform(-2.0, -1.0, 0.2),  # powers of 10\n",
    "}\n",
    "analysis = tune.run(\n",
    "    training_function,\n",
    "    config=config, \n",
    "    metric='Logloss Test',\n",
    "    mode=\"max\",\n",
    "    num_samples=48,\n",
    "    search_alg=HyperOptSearch(random_state_seed=1),\n",
    "    resume =  'AUTO',#\"ERRORED_ONLY\", \n",
    "    name='XGBoost_ros_tuning', \n",
    "    local_dir=os.path.join(os.environ['PWD'],'data/ray_results'),\n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6c554e7-11bc-4b50-8e7d-4bd65c1781b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('dp', Data_Prep()), ('ros', RandomOverSampler()),\n",
       "                ('xgb',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=0.87, colsample_bynode=1,\n",
       "                               colsample_bytree=0.8, enable_categorical=False,\n",
       "                               eval_metric='logloss', gamma=0.23235727610719414,\n",
       "                               gpu_id=-1, importance_type=None,\n",
       "                               interaction_constraints='', learning_rate=0.1,\n",
       "                               max_delta_step=0, max_depth=6,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=118,\n",
       "                               n_jobs=12, num_parallel_tree=1, predictor='auto',\n",
       "                               random_state=1, reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=1, subsample=0.78,\n",
       "                               tree_method='exact', use_label_encoder=False,\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = analysis.best_config\n",
    "config['learning_rate'] = 10 ** config['learning_rate']\n",
    "\n",
    "# Fit the best algorithm to the data.\n",
    "estimator = Pipeline([('dp', Data_Prep()), ('ros', RandomOverSampler()), \n",
    "                          ('xgb', XGBClassifier(random_state=1, eval_metric='logloss', use_label_encoder=False, **config))])\n",
    "\n",
    "estimator.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a9a0bdf-2c65-4e33-badd-001522f16101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimator pickled successfully!\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(os.environ['PWD'],'models/xgboost_ros.pkl')\n",
    "pickling_on = open(model_path,\"wb\")\n",
    "pickle.dump(estimator, pickling_on)\n",
    "pickling_on.close()\n",
    "print('estimator pickled successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b207826-ed26-4ff7-bae7-293e1d7d33e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
